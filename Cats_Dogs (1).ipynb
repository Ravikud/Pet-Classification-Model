{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cats_Dogs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFsw6PrqjGpB",
        "outputId": "e517fff2-dae3-4efa-f605-c108305d78d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfLNkPXCjUhB"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from keras.models import Sequential,load_model\n",
        "from keras.layers import Conv2D,MaxPool2D\n",
        "from keras.layers import Activation,Dropout,Dense,Flatten\n",
        "from keras import backend as k\n",
        "import numpy as np\n",
        "\n",
        "from os import listdir\n",
        "from os.path import isfile,join"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iut8sIEIsYru"
      },
      "source": [
        "img_width=150\n",
        "img_height=150\n",
        "\n",
        "train_data_dir='/content/drive/My Drive/Colab Notebooks/Images/train'\n",
        "test_data_dir='/content/drive/My Drive/Colab Notebooks/Images/test'\n",
        "train_samples=20\n",
        "validation_samples=4\n",
        "#epochs=200\n",
        "epochs=10\n",
        "batch_size=1\n",
        "#Check which backend version Theano or Tensorflow\n",
        "if(k.image_data_format() == 'channels_first'):\n",
        "  input_shape=(3,img_width,img_height)\n",
        "else:\n",
        "   input_shape=(img_width,img_height,3)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvReP3oQHZKr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLIf82YytYM7"
      },
      "source": [
        "#Apply a Sequential Model .\n",
        "model = Sequential()\n",
        "\n",
        "#Input Layer of 5*5 pixel and activation function is Relu\n",
        "model.add(Conv2D(32,(5,5),input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "#First Hidden Layer\n",
        "#Convolutional layer 2 with 32   filters of kernel size[5,5] \n",
        "model.add(Conv2D(32,(5,5)))\n",
        "model.add(Activation('relu'))\n",
        "#Pooling layer 2 with pool size[2,2] and stride 2 \n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "#Second Hidden Layer\n",
        "#Convolutional layer 2 with 64 filters of kernel size[5,5] \n",
        "model.add(Conv2D(64,(5,5)))\n",
        "model.add(Activation('relu'))\n",
        "#Pooling layer 2 with pool size[2,2] and stride 2 \n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "#Add a flatten layer\n",
        "model.add(Flatten())\n",
        "\n",
        "#Output Layer\n",
        "\n",
        "#Dense Layer Size 32\n",
        "model.add(Dense(32))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1))\n",
        "#Activation Function Softmax\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiFmA5InwkZU"
      },
      "source": [
        "import keras\n",
        "from keras import optimizers\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=keras.optimizers.Adam(lr=.0001),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UevT8TAU2zl1"
      },
      "source": [
        "# Rescale pixel values from [0, 255] to [0, 1]\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGggqFIL2_ID"
      },
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzDVQb2Y3FhM",
        "outputId": "c81ebc4a-e194-4706-fb63-f008a158baeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "  #Get all the images from the directory file\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode ='binary'\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 40 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQiKL8ru3GNN",
        "outputId": "111b5fff-496a-48b5-d53d-053707688cdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        }
      },
      "source": [
        "print(train_generator.class_indices)  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'cats': 0, 'dogs': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qVjSQeOV9cS"
      },
      "source": [
        "#REturns the next batches of images \n",
        "img,labels = next(train_generator)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eARx1ncAWHdO"
      },
      "source": [
        "from skimage import io\n",
        "\n",
        "def imshow(image_RGB):\n",
        "  io.imshow(image_RGB)\n",
        "  io.show()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awkd7OjDWbJO",
        "outputId": "4dddd745-eeb4-494c-d5d6-812bcd0619a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib  inline\n",
        "\n",
        "#Iterating through all the images batches\n",
        "img_batch,labels_batch = train_generator.next()\n",
        "\n",
        "print(len(img_batch))\n",
        "for i in range(0,len(img_batch)):\n",
        "  image = img_batch[i]\n",
        "  print(labels_batch[i])\n",
        "  imgshow(image)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-a77e13c0b862>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mimgshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'imgshow' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlWNh58GXfYu",
        "outputId": "5ee89f89-9834-43a7-c408-089bdbf75a7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "#For Validation Test\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode ='binary'\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axjbRHXLYRaX",
        "outputId": "8e85ee99-998b-471e-cc94-14d33ee766b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 856
        }
      },
      "source": [
        "#Fit the model \n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=2,\n",
        "     #epochs=100, \n",
        "     epochs=20,\n",
        "     validation_data=test_generator,\n",
        "     validation_steps=5\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "2/2 [==============================] - 0s 249ms/step - loss: 7.6246 - accuracy: 0.5000 - val_loss: 3.0498 - val_accuracy: 0.8000\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 0s 157ms/step - loss: 7.6246 - accuracy: 0.5000 - val_loss: 9.1495 - val_accuracy: 0.4000\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 0s 233ms/step - loss: 7.6246 - accuracy: 0.5000 - val_loss: 3.0498 - val_accuracy: 0.8000\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 0s 185ms/step - loss: 7.6246 - accuracy: 0.5000 - val_loss: 9.1495 - val_accuracy: 0.4000\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 0s 96ms/step - loss: 7.6246 - accuracy: 0.5000 - val_loss: 6.0997 - val_accuracy: 0.6000\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 0s 101ms/step - loss: 15.2492 - accuracy: 0.0000e+00 - val_loss: 6.0997 - val_accuracy: 0.6000\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 7.6246 - accuracy: 0.5000 - val_loss: 12.1994 - val_accuracy: 0.2000\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 0s 96ms/step - loss: 7.6246 - accuracy: 0.5000 - val_loss: 9.1495 - val_accuracy: 0.4000\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 7.6246 - accuracy: 0.5000 - val_loss: 3.0498 - val_accuracy: 0.8000\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 0s 102ms/step - loss: 15.2492 - accuracy: 0.0000e+00 - val_loss: 6.0997 - val_accuracy: 0.6000\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 0s 97ms/step - loss: 15.2492 - accuracy: 0.0000e+00 - val_loss: 6.0997 - val_accuracy: 0.6000\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 0s 102ms/step - loss: 7.6246 - accuracy: 0.5000 - val_loss: 12.1994 - val_accuracy: 0.2000\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 0s 101ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.0498 - val_accuracy: 0.8000\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 0s 143ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.1495 - val_accuracy: 0.4000\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 0s 97ms/step - loss: 7.6246 - accuracy: 0.5000 - val_loss: 9.1495 - val_accuracy: 0.4000\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 0s 99ms/step - loss: 7.6246 - accuracy: 0.5000 - val_loss: 9.1495 - val_accuracy: 0.4000\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.1495 - val_accuracy: 0.4000\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 0s 97ms/step - loss: 15.2492 - accuracy: 0.0000e+00 - val_loss: 9.1495 - val_accuracy: 0.4000\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 0s 103ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.1495 - val_accuracy: 0.4000\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 0s 96ms/step - loss: 7.6246 - accuracy: 0.5000 - val_loss: 12.1994 - val_accuracy: 0.2000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}